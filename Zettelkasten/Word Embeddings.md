---
tags:
  - Russel-n-Norvig-chap-24
---
A low-dimensional vector representing a word. Better than [[One-Hot Enconding]] because are [[dense vector]] 

They are learned *automatically* by the data. Unlikely pre-trained models, *word embeddings produced for a specific task tend to emphasise aspects of words that are useful for that task*. [[Example of a word embedding being created to solve a POS problem]]

![[Pasted image 20231101192053.png|600]]