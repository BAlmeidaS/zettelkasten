---
tags:
  - machine-learning
aliases:
  - kl divergence
---
*KL divergence* is a measure of how much two distributions are close to each other.

In information theory, kl divergence measures *the extra amount of information required to encode samples from the true distribution $\displaystyle \large P$ when using the approximate distribution $\displaystyle \large Q$*. 

On *discrete* space:
$$\displaystyle \Huge \begin{eqnarray} 
D_{KL}(P\mid\mid \dfrac{1}{w})
\infdiv[\bigg]
\end{eqnarray}$$
On *continuous* space