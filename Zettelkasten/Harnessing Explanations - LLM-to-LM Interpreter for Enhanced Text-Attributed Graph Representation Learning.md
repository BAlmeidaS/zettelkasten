---
tags:
  - paper
---
URL: https://arxiv.org/pdf/2305.19523

---

The paper combines LLMs (and LM / small language models) with GNNs to do node classification.

The paper proposes a novel method for enhancing text-attributed graph representation learning by using large language models (LLMs) to generate detailed explanations and predictions from node text attributes. These outputs are then processed by a smaller, fine-tuned language model (LM) that efficiently transforms them into fixed-length vector features suitable for graph neural networks (GNNs). This approach leverages the LLM's rich reasoning capabilities while maintaining resource efficiency and scalability, resulting in improved performance on various datasets. The smaller LM acts as an interpreter, enabling the integration of complex textual information into the GNN training process.