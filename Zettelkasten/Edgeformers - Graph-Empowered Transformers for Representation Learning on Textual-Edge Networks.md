---
tags:
  - paper
  - rate-35
---
URL: https://arxiv.org/abs/2302.11050
Review: https://openreview.net/forum?id=2YQrqe4RNv
Review average (1-5): 3
Conf: ICLR 2023

---

In this paper, the authors want to design a more expressive edge model for graph neural networks based on transformer models. They propose Edgeformers to improve edge and node representation learning by modeling texts on edges in a contextualized way. The idea is to inject rich text descriptions / context in the edge representation with a transformer architecture instead of just using a simple relation name. The AC thinks that this approach is simple but reasonable, and the authors have agreed that this paper has created a meaningful design to model edges and nodes. The authors did a great job responding to the reviewers, and one reviewer has increased their score after seeing the authors' response. Overall, we recommend an acceptance of the paper based on reviews.